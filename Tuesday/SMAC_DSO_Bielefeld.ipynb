{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ESSAI SMAC Session\n",
        "Welcome to the Euro PhD School “Data Science meets Combinatorial Optimization” session on SMAC! In the following we will guide you throught the SVM configuration example from the [SMAC repository](https://github.com/automl/SMAC3). You can also read up more details in the [SMAC documentation](https://automl.github.io/SMAC3/v2.0.1/index.html)."
      ],
      "metadata": {
        "id": "gQvo2fWeUlIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMAC Installation\n",
        "\n"
      ],
      "metadata": {
        "id": "RM5kqcaoK6B0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to install conda for colab first and then proceed with the regular smac install as described in the [SMAC](https://github.com/automl/SMAC3/tree/main) repository."
      ],
      "metadata": {
        "id": "bCl2dT48ViFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtSwY3vTJduG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff22da0-830f-4e1c-d2e8-a3c87194655e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:21\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n SMAC python=3.10\n",
        "!conda activate SMAC\n",
        "#!conda install gxx_linux-64 gcc_linux-64 swig\n",
        "!pip install smac"
      ],
      "metadata": {
        "id": "8DpofEMUKOwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: After the installation above finished, you have to restart the runtime!"
      ],
      "metadata": {
        "id": "JJQY6lRMK1EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Small Example To Validate the Installation"
      ],
      "metadata": {
        "id": "XDt9sll5Voer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now test in the following, if the installation worked by executing a tiny example."
      ],
      "metadata": {
        "id": "GGd2Mnd5UXx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ConfigSpace import Configuration, ConfigurationSpace\n",
        "\n",
        "import numpy as np\n",
        "from smac import HyperparameterOptimizationFacade, Scenario\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "\n",
        "def train(config: Configuration, seed: int = 0) -> float:\n",
        "    classifier = SVC(C=config[\"C\"], random_state=seed)\n",
        "    scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "    return 1 - np.mean(scores)\n",
        "\n",
        "\n",
        "configspace = ConfigurationSpace({\"C\": (0.100, 1000.0)})\n",
        "\n",
        "# Scenario object specifying the optimization environment\n",
        "scenario = Scenario(configspace, deterministic=True, n_trials=200)\n",
        "\n",
        "# Use SMAC to find the best configuration/hyperparameters\n",
        "smac = HyperparameterOptimizationFacade(scenario, train)\n",
        "incumbent = smac.optimize()"
      ],
      "metadata": {
        "id": "oc_NiYZVKwgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Classical Training Pipeline"
      ],
      "metadata": {
        "id": "6nxN5rITUMkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations. Now you have SMAC at your disposal. Let's give it a test ride.\n",
        "The task is to optimize the hyperparameters of a simple SVM on the Iris dataset. Usually we have some training pipeline with a dataset, a configured model and some validation procedure to check for generalization performance like this:"
      ],
      "metadata": {
        "id": "yx1MJyIcLYst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, svm\n",
        "\n",
        "# We load the iris-dataset (a widely used benchmark)\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "def train_svm()->float:\n",
        "  classifier = svm.SVC(degree=3, kernel='poly', C= 1.0, shrinking=True,  gamma='auto')\n",
        "  scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "  cost = 1-np.mean(scores)\n",
        "\n",
        "  return cost\n",
        "\n"
      ],
      "metadata": {
        "id": "jaztJVDzLfG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_svm())"
      ],
      "metadata": {
        "id": "qjAYByBqMOHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the Search Space"
      ],
      "metadata": {
        "id": "zd-9OnUDUS1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This training pipeline is a hardcoded version of our training pipeline, where we as experts already have configured a lot manually - and probably spent considerable time and effort in setting these hyperparameters, but have most likely not found a truly good choice of hyperparameters leading to reliable and reproducible results.\n",
        "\n",
        "To alleviate this situation, we want to use SMAC to automatically configure these hyperparameters for us. For this purpose, we need to define what choices SMAC should optimize over. We can express this using the [ConfigSpace](https://automl.github.io/ConfigSpace/main/) package.\n",
        "\n",
        "Let us start by selecting both the `kernel` and `C` parameter, just to get a first look into ConfigSpace:"
      ],
      "metadata": {
        "id": "BMgCJ8KiOFdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ConfigSpace import Categorical, Configuration, ConfigurationSpace, Float, Integer\n",
        "from ConfigSpace.conditions import InCondition\n",
        "\n",
        "\n",
        "# define the search space object\n",
        "cs = ConfigurationSpace(seed=0)  # The seed is mostly important for the sampling which we will see in a second.\n",
        "\n",
        "# define the hyperparameters with their default values\n",
        "kernel= Categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], default=\"poly\")\n",
        "C = Float(\"C\", (0.001, 1000.0), default=1.0, log=True) # Notice, that we define the penalty weight on a log scale!\n",
        "\n",
        "# register the hyperparameters in the search space\n",
        "cs.add_hyperparameters([kernel, C])\n"
      ],
      "metadata": {
        "id": "UaSEmeKzO_GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A nice thing about the `ConfigurationSpace` object is that it already checks the bounds of our parameters and lets us sample the search space. You can execute the following cell several times to see that it truly samples from the space and does not always return the same configuration.\n"
      ],
      "metadata": {
        "id": "891Lm2SuTACC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = cs.sample_configuration(1)\n",
        "print(config)"
      ],
      "metadata": {
        "id": "tbjzwqErTLaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, we will have to adjust our pipeline to accomodate this newly gained flexibility, like we would when we wrote a script with argparse:"
      ],
      "metadata": {
        "id": "2W3G62nbTaow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm(config:Configuration)->float:\n",
        "  config_dict = dict(config)\n",
        "  classifier = svm.SVC(degree=3, kernel=config_dict['kernel'], C=config_dict['C'], shrinking=True,  gamma='auto')\n",
        "  scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "  cost = 1-np.mean(scores)\n",
        "\n",
        "  return cost"
      ],
      "metadata": {
        "id": "8HIeUYSxThL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_svm(config)"
      ],
      "metadata": {
        "id": "a1S_zZZYT7R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a nice place to start. Now we can do a lot more elaborate stuff with the ConfigSpace package such as dealing with different types of hyperparameters (e.g. Categorical, Integer and Float or even setting up conditional hyperparameters; i.e. hyperparameters whose occurance is depending on whether or not another hyperparameter is active.) Let us formulate a rather broad search space with a few of these dependencies:"
      ],
      "metadata": {
        "id": "x5_hFzjaVv4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cs = ConfigurationSpace(seed=0)\n",
        "\n",
        "# First we create our hyperparameters\n",
        "kernel = Categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], default=\"poly\")\n",
        "C = Float(\"C\", (0.001, 1000.0), default=1.0, log=True)\n",
        "shrinking = Categorical(\"shrinking\", [True, False], default=True)\n",
        "degree = Integer(\"degree\", (1, 5), default=3)\n",
        "coef = Float(\"coef0\", (0.0, 10.0), default=0.0)\n",
        "gamma = Categorical(\"gamma\", [\"auto\", \"value\"], default=\"auto\")\n",
        "gamma_value = Float(\"gamma_value\", (0.0001, 8.0), default=1.0, log=True)\n",
        "\n",
        "# Then we create dependencies\n",
        "use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
        "use_coef = InCondition(child=coef, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
        "use_gamma = InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"])\n",
        "use_gamma_value = InCondition(child=gamma_value, parent=gamma, values=[\"value\"])\n",
        "\n",
        "# Add hyperparameters and conditions to our configspace\n",
        "cs.add_hyperparameters([kernel, C, shrinking, degree, coef, gamma, gamma_value])\n",
        "cs.add_conditions([use_degree, use_coef, use_gamma, use_gamma_value])\n",
        "\n"
      ],
      "metadata": {
        "id": "_v4MJv1VTpLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs.sample_configuration(5) # and sample n configurations"
      ],
      "metadata": {
        "id": "HjHRu_L5Wnxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course we  again need to adjust our training pipeline accordingly.\n",
        "Notice, that the gamma parameter is a bit more tricky; we can either set it to `value` or to `auto` in case of `auto` the SVM model will determine the value of gamma automatically, wheres `value` give us users the opportunity to set it ourselves - which we in turn need to set. This is why we introduced the `gamma_value` variable earlier.\n",
        "\n",
        "You can see this added complexity in the `svm.SVC` documentation:\n",
        "> gamma{‘scale’, ‘auto’} or float, default=’scale’\n",
        "> Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
        ">\n",
        ">if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) >as value of gamma,\n",
        ">\n",
        ">if ‘auto’, uses 1 / n_features\n",
        ">\n",
        ">if float, must be non-negative.\n",
        "\n"
      ],
      "metadata": {
        "id": "iuevwME7XBVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm(config: Configuration, seed: int = 0) -> float:\n",
        "    \"\"\"Creates a SVM based on a configuration and evaluates it on the\n",
        "    iris-dataset using cross-validation.\"\"\"\n",
        "    config_dict = dict(config)\n",
        "\n",
        "    # some additional magic to deal with the complex gamma hyperparameter\n",
        "    if \"gamma\" in config.keys():\n",
        "        config_dict[\"gamma\"] = config_dict[\"gamma_value\"] if config_dict[\"gamma\"] == \"value\" else \"auto\"\n",
        "        config_dict.pop(\"gamma_value\", None)\n",
        "\n",
        "    classifier = svm.SVC(**config_dict, random_state=seed)  # here we unpack the configuration and add a seed to the SVC class for reproducibility\n",
        "    scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "    cost = 1 - np.mean(scores)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "gbkTzY4XWzmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = cs.sample_configuration()\n",
        "\n",
        "print(f'Training \\n{config}\\n yields an average cross validation score of {train_svm(config, seed=0)}')"
      ],
      "metadata": {
        "id": "V-EHxQxGYhXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining the Search Space with our Training Pipeline"
      ],
      "metadata": {
        "id": "TVVKdXdZiBGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we compare this with the original pipeline, this is almost no effort and a drop-in replacement, even for rather complex search spaces. All of the design decisions we deem fit for optimization are now included and explicit. Let`s place this in a nice looking and explicit wrapper class:"
      ],
      "metadata": {
        "id": "Pu9L-OBrYcgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from ConfigSpace import Categorical, Configuration, ConfigurationSpace, Float, Integer\n",
        "from ConfigSpace.conditions import InCondition\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from smac import HyperparameterOptimizationFacade, Scenario\n",
        "\n",
        "# We load the iris-dataset (a widely used benchmark)\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "\n",
        "class SVM:\n",
        "    @property\n",
        "    def configspace(self) -> ConfigurationSpace:\n",
        "        # Build Configuration Space which defines all parameters and their ranges\n",
        "        cs = ConfigurationSpace(seed=0)\n",
        "\n",
        "        # First we create our hyperparameters\n",
        "        kernel = Categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], default=\"poly\")\n",
        "        C = Float(\"C\", (0.001, 1000.0), default=1.0, log=True)\n",
        "        shrinking = Categorical(\"shrinking\", [True, False], default=True)\n",
        "        degree = Integer(\"degree\", (1, 5), default=3)\n",
        "        coef = Float(\"coef0\", (0.0, 10.0), default=0.0)\n",
        "        gamma = Categorical(\"gamma\", [\"auto\", \"value\"], default=\"auto\")\n",
        "        gamma_value = Float(\"gamma_value\", (0.0001, 8.0), default=1.0, log=True)\n",
        "\n",
        "        # Then we create dependencies\n",
        "        use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
        "        use_coef = InCondition(child=coef, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
        "        use_gamma = InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"])\n",
        "        use_gamma_value = InCondition(child=gamma_value, parent=gamma, values=[\"value\"])\n",
        "\n",
        "        # Add hyperparameters and conditions to our configspace\n",
        "        cs.add_hyperparameters([kernel, C, shrinking, degree, coef, gamma, gamma_value])\n",
        "        cs.add_conditions([use_degree, use_coef, use_gamma, use_gamma_value])\n",
        "\n",
        "        return cs\n",
        "\n",
        "    def train(self, config: Configuration, seed: int = 0) -> float:\n",
        "        \"\"\"Creates a SVM based on a configuration and evaluates it on the\n",
        "        iris-dataset using cross-validation.\"\"\"\n",
        "        config_dict = dict(config)\n",
        "        if \"gamma\" in config.keys():\n",
        "            config_dict[\"gamma\"] = config_dict[\"gamma_value\"] if config_dict[\"gamma\"] == \"value\" else \"auto\"\n",
        "            config_dict.pop(\"gamma_value\", None)\n",
        "\n",
        "        classifier = svm.SVC(**config_dict, random_state=seed)\n",
        "        scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "        cost = 1 - np.mean(scores)\n",
        "\n",
        "        return cost\n"
      ],
      "metadata": {
        "id": "60yuQm0iaKBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVM()\n",
        "cs = classifier.configspace\n",
        "config = cs.sample_configuration()\n",
        "cost = classifier.train(config, seed=0)\n",
        "\n",
        "\n",
        "print(f'Training \\n{config}\\n yields an average cross validation score of {cost}')"
      ],
      "metadata": {
        "id": "6_28P-Yjb08k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up SMAC and optimize"
      ],
      "metadata": {
        "id": "tNxa92Q3iHMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only thing required to optimize over this search space on our pipeline is setting up our hyperparameter optimizer SMAC. There is a plethora of things we can do to configure or even extend SMAC to fit our hyperparameter optimization needs, but for now let us stick with a powerful out-of-the-box variant, called the `HyperparameterOptimizationFacade`, that comes with strong default choices for optimizing black box functions.\n",
        "\n",
        "The setup is devided into two components:\n",
        "1. The `Scenario` object which allows us to specify general information about the run like the number of trials, maximum `wall_clock_time` or the time for an individual trial (`trial_walltime_limit`) we are willing to spend during our hyperparameter optimization. We can even specify hardware constraints that terminate a trial such as `trial_mem_limit`. All of this obviously depends on our budgetary constraints -- do we have a cluster or only a small laptop that we can use to optimize our pipeline.\n",
        "2. The actual `Facade` object. This object allows us to tinker with the hyperparameter optimization process and leverage everything SMAC has to offer. (more on that later)"
      ],
      "metadata": {
        "id": "973Y4sLaaYde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scenario = Scenario(\n",
        "        classifier.configspace, # here we pass our search space.\n",
        "        n_trials=50,  # We want to run max 50 trials (combination of config and seed)\n",
        "\n",
        ")\n",
        "\n",
        "smac = HyperparameterOptimizationFacade(\n",
        "      scenario,\n",
        "      classifier.train, # here we pass our pipeline function that we want to optimize over.\n",
        "      overwrite=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "0Irivud8aVWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we are ready to optimize our model pipeline:"
      ],
      "metadata": {
        "id": "BjRvwJtPg6RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incumbent = smac.optimize()\n",
        "print(incumbent)"
      ],
      "metadata": {
        "id": "VfjLV037fk_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the HyperparameterOptimizationFacade, we have tried and tested 50 configuration-seed combinations and eventually found the one configuration that performed best on our task. This configuration is called the incumbent. It is the currently best configuration seen so far. We now know that\n",
        "\n",
        " 'C': 1.2760639488343621,\n",
        "  'kernel': 'linear',\n",
        "  'shrinking': False,\n",
        "\n",
        "is, given our budget constraints, the best model found for our task. Let uns now calculate the cost of this configuration in the following."
      ],
      "metadata": {
        "id": "vdYstMttfxce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's calculate the cost of the incumbent\n",
        "# We obviously have seen this conifguration during tuning, but we may want to make\n",
        "# see its performance on a different seed from the one that we used during training:\n",
        "incumbent_cost = smac.validate(incumbent)\n",
        "print(f\"Incumbent cost: {incumbent_cost}\")"
      ],
      "metadata": {
        "id": "rjj5hwfvfpD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bf698d-2507-4d4d-ec77-94a2ae42440c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incumbent cost: 0.013333333333333308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice and simple out of the box - right?\n",
        "\n",
        "But which configurations did it try so far?"
      ],
      "metadata": {
        "id": "RFD4X1iNhiqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'What configurations have been executed:\\n {smac.runhistory._config_ids} \\n\\n')\n",
        "print(f'Which config-seed combinations have been executed, did they succeed and what cost did they incur:')\n",
        "\n",
        "# Notice, that we guard against variability in our pipeline with multiple seeds that are averaged over\n",
        "for key, value in smac.runhistory._data.items():\n",
        "  print(key, value)"
      ],
      "metadata": {
        "id": "ycbKD9wKhh8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A More Advanced Look Into SMAC\n",
        "\n",
        "Let us have a slightly closer look at the [`HyperparameterOptimizationFacade`](https://github.com/automl/SMAC3/blob/main/smac/facade/hyperparameter_optimization_facade.py)\n",
        "\n",
        "The Facade holds many useful default components that are used during Bayesian Optimization and out of the box consists of a random forest model as a surrogate function, an Expected Improvement acquistion function, a LocalAndSortedRandomSearch acquisition maximizer and a Random Sobol initial design; i.e. it samples a share of the configurations at random based on the sobol sequence in the search space to kickstart the Bayesian Optimization.\n",
        "All of these components are configurable and exchanable to suit the user's preferences; enabling the user to tinker with the BO loop on various levels.\n",
        "\n",
        "Let's say we wanted to change the number of random configurations to sample during the initial design and wanted to change the exploration/exploitation behaviour by means of the Expected Improvement's `xi` parameter:\n"
      ],
      "metadata": {
        "id": "P2XeoLUQlrhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_design = HyperparameterOptimizationFacade.get_initial_design(scenario, n_configs=5)\n",
        "acquisition_function = HyperparameterOptimizationFacade.get_acquisition_function(scenario, xi=0.5)\n",
        "\n",
        "# Now we use SMAC to find the best hyperparameters\n",
        "smac = HyperparameterOptimizationFacade(\n",
        "    scenario,\n",
        "    classifier.train,\n",
        "    initial_design=initial_design,\n",
        "    acquisition_function=acquisition_function,\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "ULS6jbtU9lr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incumbent = smac.optimize()"
      ],
      "metadata": {
        "id": "6W4MHDQk-0dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Facades\n",
        "There are lot's of different needs when optimizing different hyperparameter optimization problems, which is why there are quite a few other facades tailored to different usecases like the `BlackBoxFacade`, `HyperbandFacade`, `MultiFidelityFacade`, `AlgorithmConfigurationFacade` or `RandomFacade` providing sensible defaults for all of these special cases with the same configurability. Find out more about them and what they are useful for in our [documentation](https://automl.github.io/SMAC3/development/3_getting_started.html#facade)"
      ],
      "metadata": {
        "id": "DDjBvBEM-zgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Features\n",
        "While SMAC is already bundled with a lot of functionallity ranging from single to multi-objective, multi-instance and multi-fidelity optimization, there are a lot of features to accomodate your concrete needs which allow you to tinker with the optimization loop. From custom [Callbacks](https://automl.github.io/SMAC3/development/advanced_usage/1_components.html#callback) at various stages during the optimization loop granting you immediate access, there are other features that shipped with the latest version like the Ask & Tell interface or the abbility to continue an optimization run. These features allow for a more interactive experience and more flexible optimization with the human back in the loop. In the following, we will quickly go over some of these features.\n",
        "\n",
        "## Ask & Tell\n",
        "\n",
        "The Ask & Tell interface can be used to write a custom SMAC optimization loop for very specific use cases. The underlying idea is that one can very readily ask configurations of SMAC and actively train them before adding the results back to SMAC.\n",
        "\n"
      ],
      "metadata": {
        "id": "avfu4Pd8o4kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smac.runhistory.dataclasses import TrialValue, TrialInfo\n",
        "\n",
        "smac = HyperparameterOptimizationFacade(\n",
        "      scenario,\n",
        "      classifier.train,\n",
        "      overwrite=True,\n",
        "  )\n",
        "\n",
        "# We can ask SMAC which trials should be evaluated next\n",
        "\n",
        "for _ in range(10):\n",
        "    info = smac.ask()   # returns a TrialInfo object\n",
        "\n",
        "    assert info.seed is not None\n",
        "\n",
        "    cost = classifier.train(info.config, seed=info.seed)\n",
        "    value = TrialValue(cost=cost, time=0.5)\n",
        "\n",
        "    smac.tell(info, value)\n",
        "\n",
        "# Execute the rest of the optimization loop\n",
        "incumbent = smac.optimize() # Caution: The user's tials are also counted in `n_trials`\n"
      ],
      "metadata": {
        "id": "PJSlOA9MD62H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks & Continuation\n",
        "\n",
        "In this combined example, we define a callback that is terminating SMAC prematurely after `stop_after` number of steps by inserting it right after the (internally used) tell at the end of every step of the BO loop. After terminating the first smac instance once the first 10 configurations are executed, we let smac find the runhistory in the current directory automatically and continue from there with the same amount of trials - as configured by the scenario object."
      ],
      "metadata": {
        "id": "mm8-mqT6o6ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smac import Callback\n",
        "from smac.main.smbo import SMBO\n",
        "\n",
        "class StopCallback(Callback):\n",
        "    def __init__(self, stop_after: int):\n",
        "        self._stop_after = stop_after\n",
        "\n",
        "    def on_tell_end(self, smbo: SMBO, info: TrialInfo, value: TrialValue) -> bool | None:\n",
        "        \"\"\"Called after the stats are updated and the trial is added to the runhistory. Optionally, returns false\n",
        "        to gracefully stop the optimization.\n",
        "        \"\"\"\n",
        "        if smbo.runhistory.finished == self._stop_after:\n",
        "            return False\n",
        "\n",
        "        return None"
      ],
      "metadata": {
        "id": "2pCiUEJcG51i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario object specifying the optimization \"environment\"\n",
        "# here we assume the target function to be deterministic, which is why we only need one seed!\n",
        "scenario = Scenario(classifier.configspace, deterministic=True, n_trials=50)\n",
        "stop_after = 10\n",
        "\n",
        "# Now we use SMAC to find the best hyperparameters\n",
        "smac = HyperparameterOptimizationFacade(\n",
        "    scenario,\n",
        "    classifier.train,  # We pass the target function here\n",
        "    callbacks=[StopCallback(stop_after=stop_after)],\n",
        "    overwrite=True,  # Overrides any previous results that are found that are inconsistent with the meta-data\n",
        ")\n",
        "\n",
        "incumbent = smac.optimize()\n",
        "assert smac.runhistory.finished == stop_after\n",
        "\n",
        "smac1trials = smac.runhistory._data\n",
        "print(f'These configurations have been executed in the first smac iteration: {smac1trials}')\n",
        "\n",
        "scenario = Scenario(classifier.configspace, deterministic=True, n_trials=50)\n",
        "\n",
        "# Now, we want to continue the optimization\n",
        "# Make sure, we don't overwrite the last run\n",
        "smac2 = HyperparameterOptimizationFacade(\n",
        "    scenario,\n",
        "    classifier.train,\n",
        "    overwrite=False,\n",
        ")\n",
        "\n",
        "# Check whether we have the same incumbent after 'loading' the latest smac run from disk\n",
        "\n",
        "assert smac.intensifier.get_incumbent() == smac2.intensifier.get_incumbent()\n",
        "assert smac2.runhistory.finished == stop_after\n",
        "\n",
        "# And now we finish the optimization\n",
        "incumbent2 = smac2.optimize()\n"
      ],
      "metadata": {
        "id": "Qki2SjZ6nKvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smac2trials = smac2.runhistory._data\n",
        "print(f'These Trials have been executed in the continuation:\\n ')\n",
        "for key in sorted(set(smac2trials) - set(smac1trials), key = lambda trialkey: trialkey.config_id):\n",
        "  print(key)"
      ],
      "metadata": {
        "id": "7CGZXOliIJCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are at the end of the guided part of this tutorial. We suggest that you know try to play around with the code explained above and change some parts with the help of the [SMAC documentation](https://automl.github.io/SMAC3/development/3_getting_started.html). Some things you can try are:\n",
        "* Exchange the dataset by a more complicated one.\n",
        "* Exchange the SVM to be configured with a Random Forest. This includes exchanging the model itself, but also adapting the configuration space.\n",
        "* You can also play around with using different SMAC facades (as discussed above) and see how that influences the performance of your model. This also includes adjusting SMAC's hyperparameters themselves.\n",
        "* You can also try to implement your own HPO tool by leveragint the ask and tell interface explained above.\n"
      ],
      "metadata": {
        "id": "y-jTXKUWDFZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This brings us to the end of this small SMAC tutorial. We hope you had a lot of fun trying SMAC out and got some insights into how to use it! For more details checkout the [SMAC documentation](https://automl.github.io/SMAC3/development/3_getting_started.html). If you want to get deeper insights into how an optimization run worked and analyze it, you might also want to have a look at our tool [DeepCave](https://github.com/automl/DeepCAVE), which allows such deep analyses."
      ],
      "metadata": {
        "id": "jRChPGcnQA6y"
      }
    }
  ]
}